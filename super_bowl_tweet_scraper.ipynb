{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "XrznqrzpIJVI",
    "outputId": "597a0662-6820-4ac1-b4a3-59df8d3eb8f9"
   },
   "outputs": [],
   "source": [
    "# You can store secrets in a file or in the form of environment variables during production.\n",
    "# NEVER store keys directly on notebook.\n",
    "\n",
    "with open('secrets.txt', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "\n",
    "import tweepy \n",
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "\n",
    "consumer_key = data[0]\n",
    "consumer_secret = data[1]\n",
    "access_key = data[2]\n",
    "access_secret = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21bRvTQ-30SN"
   },
   "outputs": [],
   "source": [
    "def get_user_tweets(screen_name, num=0):\n",
    "    #Twitter only allows access to a users most recent 3000 tweets with this method\n",
    "    num = 3000 if num > 3000 else num\n",
    "    max_num_per_call = 200\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "    num -= curr_count\n",
    "\n",
    "    new_tweets = api.user_timeline(screen_name=screen_name, count=curr_count)\n",
    "    \n",
    "    tweet = new_tweets[0]\n",
    "    print(f\"Location of username {screen_name} is: {tweet.user.location}\\n\")\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "\n",
    "    print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while num > 0:\n",
    "        print(f\"Getting tweets before {oldest}\")\n",
    "        \n",
    "        curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.user_timeline(screen_name = screen_name, count=curr_count, max_id=oldest)\n",
    "        num -= curr_count\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.text.encode(\"utf-8\")] for tweet in alltweets]\n",
    "    df = pd.DataFrame(outtweets, columns=[\"id\",\"created_at\",\"text\"])\n",
    "    df.to_csv(f\"user_{screen_name}.csv\", index=False)\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4nuDmeIGWsJ"
   },
   "outputs": [],
   "source": [
    "states = {\n",
    "    'AL': 'Alabama',\n",
    "    'AK': 'Alaska',\n",
    "    'AZ': 'Arizona',\n",
    "    'AR': 'Arkansas',\n",
    "    'CA': 'California',\n",
    "    'CO': 'Colorado',\n",
    "    'CT': 'Connecticut',\n",
    "    'DE': 'Delaware',\n",
    "    'DC': 'District of Columbia',\n",
    "    'FL': 'Florida',\n",
    "    'GA': 'Georgia',\n",
    "    'HI': 'Hawaii',\n",
    "    'ID': 'Idaho',\n",
    "    'IL': 'Illinois',\n",
    "    'IN': 'Indiana',\n",
    "    'IA': 'Iowa',\n",
    "    'KS': 'Kansas',\n",
    "    'KY': 'Kentucky',\n",
    "    'LA': 'Louisiana',\n",
    "    'ME': 'Maine',\n",
    "    'MD': 'Maryland',\n",
    "    'MA': 'Massachusetts',\n",
    "    'MI': 'Michigan',\n",
    "    'MN': 'Minnesota',\n",
    "    'MS': 'Mississippi',\n",
    "    'MO': 'Missouri',\n",
    "    'MT': 'Montana',\n",
    "    'NE': 'Nebraska',\n",
    "    'NV': 'Nevada',\n",
    "    'NH': 'New Hampshire',\n",
    "    'NJ': 'New Jersey',\n",
    "    'NM': 'New Mexico',\n",
    "    'NY': 'New York',\n",
    "    'NC': 'North Carolina',\n",
    "    'ND': 'North Dakota',\n",
    "    'OH': 'Ohio',\n",
    "    'OK': 'Oklahoma',\n",
    "    'OR': 'Oregon',\n",
    "    'PA': 'Pennsylvania',\n",
    "    'RI': 'Rhode Island',\n",
    "    'SC': 'South Carolina',\n",
    "    'SD': 'South Dakota',\n",
    "    'TN': 'Tennessee',\n",
    "    'TX': 'Texas',\n",
    "    'UT': 'Utah',\n",
    "    'VT': 'Vermont',\n",
    "    'VA': 'Virginia',\n",
    "    'WA': 'Washington',\n",
    "    'WV': 'West Virginia',\n",
    "    'WI': 'Wisconsin',\n",
    "    'WY': 'Wyoming'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nt_thZXW-7It"
   },
   "outputs": [],
   "source": [
    "def get_query_tweets(query, num=0):\n",
    "    #num = 3000 if num > 3000 else num\n",
    "    max_num_per_call = 100\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "    num -= curr_count\n",
    "\n",
    "    new_tweets = api.search(q=query, count=curr_count)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while num > 0:\n",
    "        print(f\"Getting tweets before {oldest}\")\n",
    "        \n",
    "        curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.search(q=query, count=curr_count, max_id=oldest)\n",
    "        num -= curr_count\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.user.verified, tweet.user.screen_name, tweet.text.encode(\"utf-8\"),\\\n",
    "                  tweet.user.location] for tweet in alltweets]\n",
    "    df = pd.DataFrame(outtweets, columns=[\"id\", \"created_at\", 'verified', 'username', \"text\",\\\n",
    "                                          \"location\"])\n",
    "    df.to_csv(f\"query_{query}.csv\", index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "ykzq6zblCILU",
    "outputId": "0edd0801-98e9-4126-a7f3-a25683407eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets downloaded so far\n",
      "Getting tweets before 1224042709477781503\n",
      "200 tweets downloaded so far\n",
      "Getting tweets before 1224042684999925760\n",
      "300 tweets downloaded so far\n",
      "Getting tweets before 1224042660366835714\n",
      "400 tweets downloaded so far\n",
      "Getting tweets before 1224042635603648511\n",
      "500 tweets downloaded so far\n",
      "Getting tweets before 1224042610320445441\n",
      "600 tweets downloaded so far\n",
      "Getting tweets before 1224042587943624703\n",
      "700 tweets downloaded so far\n",
      "Getting tweets before 1224042564883382272\n",
      "800 tweets downloaded so far\n",
      "Getting tweets before 1224042544213962759\n",
      "900 tweets downloaded so far\n",
      "Getting tweets before 1224042522630139904\n",
      "1000 tweets downloaded so far\n",
      "Getting tweets before 1224042500911980543\n",
      "1100 tweets downloaded so far\n",
      "Getting tweets before 1224042476366942210\n",
      "1200 tweets downloaded so far\n",
      "Getting tweets before 1224042455562981376\n",
      "1300 tweets downloaded so far\n",
      "Getting tweets before 1224042432569974788\n",
      "1400 tweets downloaded so far\n",
      "Getting tweets before 1224042412022079487\n",
      "1500 tweets downloaded so far\n",
      "Getting tweets before 1224042393898496004\n",
      "1600 tweets downloaded so far\n",
      "Getting tweets before 1224042372272549887\n",
      "1700 tweets downloaded so far\n",
      "Getting tweets before 1224042347790569472\n",
      "1800 tweets downloaded so far\n",
      "Getting tweets before 1224042327150252031\n",
      "1900 tweets downloaded so far\n",
      "Getting tweets before 1224042306560503807\n",
      "2000 tweets downloaded so far\n",
      "Getting tweets before 1224042283546353663\n",
      "2100 tweets downloaded so far\n",
      "Getting tweets before 1224042264164478978\n",
      "2200 tweets downloaded so far\n",
      "Getting tweets before 1224042244031832064\n",
      "2300 tweets downloaded so far\n",
      "Getting tweets before 1224042220845785089\n",
      "2400 tweets downloaded so far\n",
      "Getting tweets before 1224042201954447359\n",
      "2500 tweets downloaded so far\n",
      "Getting tweets before 1224042180496502783\n",
      "2600 tweets downloaded so far\n",
      "Getting tweets before 1224042161357893634\n",
      "2700 tweets downloaded so far\n",
      "Getting tweets before 1224042136645046271\n",
      "2800 tweets downloaded so far\n",
      "Getting tweets before 1224042118798364671\n",
      "2900 tweets downloaded so far\n",
      "Getting tweets before 1224042093942689794\n",
      "3000 tweets downloaded so far\n",
      "Getting tweets before 1224042070307954687\n",
      "3100 tweets downloaded so far\n",
      "Getting tweets before 1224042047348314113\n",
      "3200 tweets downloaded so far\n",
      "Getting tweets before 1224042025282101247\n",
      "3300 tweets downloaded so far\n",
      "Getting tweets before 1224042004952252418\n",
      "3400 tweets downloaded so far\n",
      "Getting tweets before 1224041980994306047\n",
      "3500 tweets downloaded so far\n",
      "Getting tweets before 1224041957510479871\n",
      "3600 tweets downloaded so far\n",
      "Getting tweets before 1224041931233267711\n",
      "3700 tweets downloaded so far\n",
      "Getting tweets before 1224041908613283840\n",
      "3800 tweets downloaded so far\n",
      "Getting tweets before 1224041882793082879\n",
      "3900 tweets downloaded so far\n",
      "Getting tweets before 1224041859812511743\n",
      "4000 tweets downloaded so far\n",
      "Getting tweets before 1224041833572880383\n",
      "4100 tweets downloaded so far\n",
      "Getting tweets before 1224041808541282303\n",
      "4200 tweets downloaded so far\n",
      "Getting tweets before 1224041784918982655\n",
      "4300 tweets downloaded so far\n",
      "Getting tweets before 1224041762097942530\n",
      "4400 tweets downloaded so far\n",
      "Getting tweets before 1224041736265179137\n",
      "4500 tweets downloaded so far\n",
      "Getting tweets before 1224041713645256704\n",
      "4600 tweets downloaded so far\n",
      "Getting tweets before 1224041687011483647\n",
      "4700 tweets downloaded so far\n",
      "Getting tweets before 1224041661094756351\n",
      "4800 tweets downloaded so far\n",
      "Getting tweets before 1224041636168110079\n",
      "4900 tweets downloaded so far\n",
      "Getting tweets before 1224041612986048511\n",
      "5000 tweets downloaded so far\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224042733859409921</td>\n",
       "      <td>2020-02-02 18:51:44</td>\n",
       "      <td>False</td>\n",
       "      <td>pnix49</td>\n",
       "      <td>b'RT @maxcredits: Remember when the Super Bowl...</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1224042733712629760</td>\n",
       "      <td>2020-02-02 18:51:43</td>\n",
       "      <td>False</td>\n",
       "      <td>kevjones5</td>\n",
       "      <td>b'RT @finalfourcast: Head on over to our Insta...</td>\n",
       "      <td>morgantown,wv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1224042733658046465</td>\n",
       "      <td>2020-02-02 18:51:43</td>\n",
       "      <td>False</td>\n",
       "      <td>kewannadabrat</td>\n",
       "      <td>b'RT @kend0llass: this the first year i could ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1224042733326622721</td>\n",
       "      <td>2020-02-02 18:51:43</td>\n",
       "      <td>False</td>\n",
       "      <td>tinowilliams23</td>\n",
       "      <td>b'High five \\xf0\\x9f\\x99\\x8b\\xf0\\x9f\\x8f\\xbd\\x...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1224042733314224129</td>\n",
       "      <td>2020-02-02 18:51:43</td>\n",
       "      <td>False</td>\n",
       "      <td>ThisIsAnch</td>\n",
       "      <td>b'I can\\xe2\\x80\\x99t wait until this day next ...</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          created_at  verified        username  \\\n",
       "0  1224042733859409921 2020-02-02 18:51:44     False          pnix49   \n",
       "1  1224042733712629760 2020-02-02 18:51:43     False       kevjones5   \n",
       "2  1224042733658046465 2020-02-02 18:51:43     False   kewannadabrat   \n",
       "3  1224042733326622721 2020-02-02 18:51:43     False  tinowilliams23   \n",
       "4  1224042733314224129 2020-02-02 18:51:43     False      ThisIsAnch   \n",
       "\n",
       "                                                text          location  \n",
       "0  b'RT @maxcredits: Remember when the Super Bowl...                TN  \n",
       "1  b'RT @finalfourcast: Head on over to our Insta...     morgantown,wv  \n",
       "2  b'RT @kend0llass: this the first year i could ...                    \n",
       "3  b'High five \\xf0\\x9f\\x99\\x8b\\xf0\\x9f\\x8f\\xbd\\x...                    \n",
       "4  b'I can\\xe2\\x80\\x99t wait until this day next ...  Jacksonville, FL  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in the search query\n",
    "df_new = get_query_tweets(\"Super Bowl\", 5000)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_full = df.append(df_new, ignore_index = True)\n",
    "df_full = df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop_duplicates().to_csv('super_bowl_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tweepy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
