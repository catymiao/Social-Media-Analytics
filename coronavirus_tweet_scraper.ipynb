{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "XrznqrzpIJVI",
    "outputId": "597a0662-6820-4ac1-b4a3-59df8d3eb8f9"
   },
   "outputs": [],
   "source": [
    "# You can store secrets in a file or in the form of environment variables during production.\n",
    "# NEVER store keys directly on notebook.\n",
    "\n",
    "with open('secrets.txt', 'r') as file:\n",
    "    data = file.read().split('\\n')\n",
    "\n",
    "import tweepy \n",
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "\n",
    "consumer_key = data[0]\n",
    "consumer_secret = data[1]\n",
    "access_key = data[2]\n",
    "access_secret = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nt_thZXW-7It"
   },
   "outputs": [],
   "source": [
    "def get_query_tweets(query, num=0):\n",
    "    #num = 3000 if num > 3000 else num\n",
    "    max_num_per_call = 100\n",
    "\n",
    "    #authorize twitter, initialize tweepy\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    \n",
    "    #initialize a list to hold all the tweepy Tweets\n",
    "    alltweets = []    \n",
    "    \n",
    "    #make initial request for most recent tweets (200 is the maximum allowed count)\n",
    "    curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "    num -= curr_count\n",
    "\n",
    "    new_tweets = api.search(q=query, count=curr_count)\n",
    "    \n",
    "    #save most recent tweets\n",
    "    alltweets.extend(new_tweets)\n",
    "    \n",
    "    #save the id of the oldest tweet less one\n",
    "    oldest = alltweets[-1].id - 1\n",
    "    \n",
    "    print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "\n",
    "    #keep grabbing tweets until there are no tweets left to grab\n",
    "    while num > 0:\n",
    "        print(f\"Getting tweets before {oldest}\")\n",
    "        \n",
    "        curr_count = max_num_per_call if num > max_num_per_call else num\n",
    "\n",
    "        #all subsiquent requests use the max_id param to prevent duplicates\n",
    "        new_tweets = api.search(q=query, count=curr_count, max_id=oldest)\n",
    "        num -= curr_count\n",
    "        \n",
    "        #save most recent tweets\n",
    "        alltweets.extend(new_tweets)\n",
    "        \n",
    "        #update the id of the oldest tweet less one\n",
    "        oldest = alltweets[-1].id - 1\n",
    "        \n",
    "        print(f\"{len(alltweets)} tweets downloaded so far\")\n",
    "    \n",
    "    #transform the tweepy tweets into a 2D array that will populate the csv    \n",
    "    outtweets = [[tweet.id_str, tweet.created_at, tweet.user.verified, tweet.user.screen_name,\\\n",
    "                  tweet.text.encode(\"utf-8\"), tweet.user.location, tweet.user.listed_count,\\\n",
    "                  tweet.user.followers_count, tweet.retweet_count] for tweet in alltweets]\n",
    "    df = pd.DataFrame(outtweets, columns=[\"id\", \"created_at\", 'verified', 'username', \"text\",\\\n",
    "                                          \"location\", \"listed_count\", \"follower_count\",\\\n",
    "                                          \"retweet_count\"])\n",
    "\n",
    "    df.to_csv(f\"query_{query}.csv\", index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "colab_type": "code",
    "id": "ykzq6zblCILU",
    "outputId": "0edd0801-98e9-4126-a7f3-a25683407eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets downloaded so far\n",
      "Getting tweets before 1226604368281075713\n",
      "200 tweets downloaded so far\n",
      "Getting tweets before 1226604327143428096\n",
      "300 tweets downloaded so far\n",
      "Getting tweets before 1226604283904217087\n",
      "400 tweets downloaded so far\n",
      "Getting tweets before 1226604239436337153\n",
      "500 tweets downloaded so far\n",
      "Getting tweets before 1226604194288852993\n",
      "600 tweets downloaded so far\n",
      "Getting tweets before 1226604162009436160\n",
      "700 tweets downloaded so far\n",
      "Getting tweets before 1226604121387606022\n",
      "800 tweets downloaded so far\n",
      "Getting tweets before 1226604075980070912\n",
      "900 tweets downloaded so far\n",
      "Getting tweets before 1226604030815854591\n",
      "1000 tweets downloaded so far\n",
      "Getting tweets before 1226603984879849472\n",
      "1100 tweets downloaded so far\n",
      "Getting tweets before 1226603940243963904\n",
      "1200 tweets downloaded so far\n",
      "Getting tweets before 1226603894849052671\n",
      "1300 tweets downloaded so far\n",
      "Getting tweets before 1226603849638699019\n",
      "1400 tweets downloaded so far\n",
      "Getting tweets before 1226603802209312767\n",
      "1500 tweets downloaded so far\n",
      "Getting tweets before 1226603755996663807\n",
      "1600 tweets downloaded so far\n",
      "Getting tweets before 1226603708328398854\n",
      "1700 tweets downloaded so far\n",
      "Getting tweets before 1226603661675159551\n",
      "1800 tweets downloaded so far\n",
      "Getting tweets before 1226603616737353733\n",
      "1900 tweets downloaded so far\n",
      "Getting tweets before 1226603565709496322\n",
      "2000 tweets downloaded so far\n",
      "Getting tweets before 1226603520406589441\n",
      "2100 tweets downloaded so far\n",
      "Getting tweets before 1226603471740309513\n",
      "2200 tweets downloaded so far\n",
      "Getting tweets before 1226603426529914886\n",
      "2300 tweets downloaded so far\n",
      "Getting tweets before 1226603381315325952\n",
      "2400 tweets downloaded so far\n",
      "Getting tweets before 1226603337040244742\n",
      "2500 tweets downloaded so far\n",
      "Getting tweets before 1226603279674535935\n",
      "2600 tweets downloaded so far\n",
      "Getting tweets before 1226603240545906687\n",
      "2700 tweets downloaded so far\n",
      "Getting tweets before 1226603189480411141\n",
      "2800 tweets downloaded so far\n",
      "Getting tweets before 1226603141610778625\n",
      "2900 tweets downloaded so far\n",
      "Getting tweets before 1226603090801037315\n",
      "3000 tweets downloaded so far\n",
      "Getting tweets before 1226603047020834815\n",
      "3100 tweets downloaded so far\n",
      "Getting tweets before 1226603003072827392\n",
      "3200 tweets downloaded so far\n",
      "Getting tweets before 1226602954943270912\n",
      "3300 tweets downloaded so far\n",
      "Getting tweets before 1226602908193640454\n",
      "3400 tweets downloaded so far\n",
      "Getting tweets before 1226602862853140482\n",
      "3500 tweets downloaded so far\n",
      "Getting tweets before 1226602809644154881\n",
      "3600 tweets downloaded so far\n",
      "Getting tweets before 1226602763460730879\n",
      "3700 tweets downloaded so far\n",
      "Getting tweets before 1226602722897649663\n",
      "3800 tweets downloaded so far\n",
      "Getting tweets before 1226602678911995904\n",
      "3900 tweets downloaded so far\n",
      "Getting tweets before 1226602636717236223\n",
      "4000 tweets downloaded so far\n",
      "Getting tweets before 1226602587169923071\n",
      "4100 tweets downloaded so far\n",
      "Getting tweets before 1226602547164700677\n",
      "4200 tweets downloaded so far\n",
      "Getting tweets before 1226602503053217797\n",
      "4300 tweets downloaded so far\n",
      "Getting tweets before 1226602463437950977\n",
      "4400 tweets downloaded so far\n",
      "Getting tweets before 1226602424510615552\n",
      "4500 tweets downloaded so far\n",
      "Getting tweets before 1226602378704642049\n",
      "4600 tweets downloaded so far\n",
      "Getting tweets before 1226602331388760065\n",
      "4700 tweets downloaded so far\n",
      "Getting tweets before 1226602292528517121\n",
      "4800 tweets downloaded so far\n",
      "Getting tweets before 1226602253689196544\n",
      "4900 tweets downloaded so far\n",
      "Getting tweets before 1226602217253330949\n",
      "5000 tweets downloaded so far\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>verified</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>location</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1226604413164408832</td>\n",
       "      <td>2020-02-09 20:30:55</td>\n",
       "      <td>False</td>\n",
       "      <td>mochihitsugi</td>\n",
       "      <td>b'RT @IGN: The Animal Crossing-themed Nintendo...</td>\n",
       "      <td>hell</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1226604412426166272</td>\n",
       "      <td>2020-02-09 20:30:55</td>\n",
       "      <td>False</td>\n",
       "      <td>RocktagonBoss</td>\n",
       "      <td>b'RT @EM_KA_17: \\xf0\\x9f\\x92\\xa5 SUCCESS again...</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>217</td>\n",
       "      <td>2813</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226604410786193420</td>\n",
       "      <td>2020-02-09 20:30:55</td>\n",
       "      <td>False</td>\n",
       "      <td>DavidLenlag</td>\n",
       "      <td>b'RT @jenniferatntd: Called a friend in #China...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1226604410765271041</td>\n",
       "      <td>2020-02-09 20:30:55</td>\n",
       "      <td>False</td>\n",
       "      <td>ericammbenitez</td>\n",
       "      <td>b'RT @hanalfabeto: Jimena Bar\\xc3\\xb3n ya est\\...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>2145</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1226604410589020161</td>\n",
       "      <td>2020-02-09 20:30:55</td>\n",
       "      <td>False</td>\n",
       "      <td>GailWil87987475</td>\n",
       "      <td>b'RT @marklevinshow: Our new Middle East frien...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>218</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id          created_at  verified         username  \\\n",
       "0  1226604413164408832 2020-02-09 20:30:55     False     mochihitsugi   \n",
       "1  1226604412426166272 2020-02-09 20:30:55     False    RocktagonBoss   \n",
       "2  1226604410786193420 2020-02-09 20:30:55     False      DavidLenlag   \n",
       "3  1226604410765271041 2020-02-09 20:30:55     False   ericammbenitez   \n",
       "4  1226604410589020161 2020-02-09 20:30:55     False  GailWil87987475   \n",
       "\n",
       "                                                text       location  \\\n",
       "0  b'RT @IGN: The Animal Crossing-themed Nintendo...           hell   \n",
       "1  b'RT @EM_KA_17: \\xf0\\x9f\\x92\\xa5 SUCCESS again...  Las Vegas, NV   \n",
       "2  b'RT @jenniferatntd: Called a friend in #China...                  \n",
       "3  b'RT @hanalfabeto: Jimena Bar\\xc3\\xb3n ya est\\...                  \n",
       "4  b'RT @marklevinshow: Our new Middle East frien...                  \n",
       "\n",
       "   listed_count  follower_count  retweet_count  \n",
       "0             0              68            150  \n",
       "1           217            2813            141  \n",
       "2             0              81            728  \n",
       "3             6            2145            317  \n",
       "4             0             218            440  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in the search query\n",
    "df_new = get_query_tweets(\"Coronavirus\", 5000)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop_duplicates().to_csv('coronavirus_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "tweepy.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
